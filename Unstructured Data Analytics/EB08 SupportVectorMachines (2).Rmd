---
title: "Optical Character Recognition with Support Vector Machines"
subtitle: "Unstructured Data Analytics"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: lumen
    highlight: zenburn
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

For this exercise, we'll train a **Support Vector Machine** model for Optical Character Recognition (OCR). OCR is the process of finding and recognizing text within an image. The image can be in the form of a screenshot, a scanned document, a picture, etc. The dataset we will be working with contains *20,000* examples of *26* English alphabet capital letters as printed using *20* different randomly reshaped and distorted black and white fonts. Some pre-processing was done to convert the images to *glyphs*. Each letter (glyph) is represented by *16* statistical attributes.

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
```

## 1. Collect the Data
Let's begin by importing and previewing the letters dataset.

```{r}
letters <- read_csv("https://s3.amazonaws.com/notredame.analytics.data/letters.csv")
letters <- letters %>% mutate(letter = as.factor(letter))
head(letters)
```

## 2. Explore and Prepare the Data
Next, we split our data into training and test sets.

```{r}
RNGkind(sample.kind = "Rounding")
set.seed(1234)
sample_set <- createDataPartition(y = letters$letter, p = .8, list = FALSE)
letters_train <- letters[sample_set, ]
letters_test <- letters[-sample_set, ]
```

## 3. Train the Model
To train an SVM model, we set the method of the caret `train()` function to `"svmLinear"`, which is a simple linear kernel. We also set the cost (`C`) to 1 and use 3-fold cross-validation to evaluate performance. Note that we also had to load the `kernlab` package which is required for the method.

```{r}
library(kernlab)
set.seed(1234)
letters_mod <- train(
  letter ~ .,
  data = letters_train,
  method = "svmLinear",
  trControl = trainControl(method = "cv", number = 3),
  tuneGrid = expand.grid(C = 1)
)
```


## 4. Evaluate the Model
Using the model, let's attempt to predict the labels of the letters in the `letters_test` dataset. 

```{r}
letters_pred <- predict(letters_mod, letters_test)
head(letters_pred)
```

With our predictions, we can generate a confusion matrix.

```{r}
letters_matrix <- confusionMatrix(letters_pred, letters_test$letter)
letters_matrix$table
```

**Question:** Why does this confusion matrix look different from the ones we've seen before?

We can also get numeric performance metrics (accuracy and kappa only) for the model against the test data.

```{r}
library(broom)
tidy(letters_matrix) %>%
  filter(term %in% c('accuracy','kappa')) %>%
  select(term, estimate) %>%
  pivot_wider(names_from = term, values_from = estimate)
```

Not too bad! I suspect we can do better.

**Question:** Why do you think we limited our focus to just Accuracy and Kappa?

## 5. Improve the Model
To improve the performance of our model, let's set the method of the caret `train()` function to `"svmRadialCost"`. This means that we intend to use the Gaussian RBF kernel. **Note that this may take a while to complete!**

```{r}
set.seed(1234)
letters_mod <- train(
  letter ~ .,
  data = letters_train,
  method = "svmRadialCost",
  trControl = trainControl(method = "cv", number = 3),
  tuneGrid = expand.grid(C = 1)
)
```

```{r}
letters_mod
```


Now, let's see see how our new model performs against the test set.

```{r}
letters_mod %>%
  predict(letters_test) %>%
  confusionMatrix(letters_test$letter) %>%
  tidy() %>%
  filter(term %in% c('accuracy','kappa')) %>%
  select(term, estimate) %>%
  pivot_wider(names_from = term, values_from = estimate)
```

Look at that. By simply changing the kernel, we significantly improved our model's performance.

**Question:** What else would you recommend that we do in order to further improve the performance of our model?

